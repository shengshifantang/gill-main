#!/usr/bin/env python3
"""
å‡†å¤‡æ··åˆè®­ç»ƒæ•°æ®ï¼ˆ15k é»„é‡‘æ•°æ® + 50k é€šç”¨æ•°æ®ï¼‰

ç­–ç•¥ï¼š
- 15k Layout Data: å¸¦ç²¾ç¡® BBox çš„é»„é‡‘æ•°æ®
- 50k General Data: ä» Wukong éšæœºæŠ½å–ï¼Œæ—  BBoxï¼ˆæˆ–å…¨å›¾ BBoxï¼‰

ç”¨äºé˜²æ­¢è¿‡æ‹Ÿåˆå’Œç¾éš¾æ€§é—å¿˜ã€‚

Usage:
    python scripts/prepare_mixed_training_data.py \
        --layout-data data/layout_dataset_final_15k.jsonl \
        --general-data data/wukong_release \
        --output-jsonl data/mixed_training_65k.jsonl \
        --layout-ratio 0.3 \
        --general-count 50000
"""

import argparse
import json
import os
import random
import pandas as pd
from typing import List, Dict
from tqdm import tqdm


def load_layout_data(layout_file: str) -> List[Dict]:
    """åŠ è½½å¸¦å¸ƒå±€çš„é»„é‡‘æ•°æ®"""
    samples = []
    with open(layout_file, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                samples.append(json.loads(line))
    return samples


def load_general_data(wukong_dir: str, num_samples: int) -> List[Dict]:
    """ä» Wukong æ•°æ®é›†ä¸­éšæœºæŠ½å–é€šç”¨æ•°æ®ï¼ˆæ— å¸ƒå±€ï¼‰"""
    samples = []
    
    # æ”¶é›†æ‰€æœ‰ CSV æ–‡ä»¶
    csv_files = []
    if os.path.isdir(wukong_dir):
        for root, dirs, files in os.walk(wukong_dir):
            for f in files:
                if f.endswith('.csv'):
                    csv_files.append(os.path.join(root, f))
    elif os.path.isfile(wukong_dir):
        csv_files = [wukong_dir]
    
    if not csv_files:
        print(f"âš ï¸ æœªæ‰¾åˆ° Wukong æ•°æ®æ–‡ä»¶: {wukong_dir}")
        return samples
    
    print(f"ğŸ“Š ä» {len(csv_files)} ä¸ª CSV æ–‡ä»¶ä¸­æŠ½å–é€šç”¨æ•°æ®...")
    
    # éšæœºæ‰“ä¹±æ–‡ä»¶é¡ºåº
    random.shuffle(csv_files)
    
    # ä»å¤šä¸ªæ–‡ä»¶ä¸­æŠ½å–
    chunk_size = 10000
    for csv_file in csv_files:
        if len(samples) >= num_samples:
            break
        
        try:
            for chunk in pd.read_csv(csv_file, chunksize=chunk_size, encoding='utf-8'):
                if len(samples) >= num_samples:
                    break
                
                for _, row in chunk.iterrows():
                    if len(samples) >= num_samples:
                        break
                    
                    caption = str(row.get('caption', '') or row.get('text', '')).strip()
                    if not caption or len(caption) < 5:
                        continue
                    
                    # æ„é€ é€šç”¨æ•°æ®æ ·æœ¬ï¼ˆæ— å¸ƒå±€ä¿¡æ¯ï¼‰
                    sample = {
                        'caption': caption,
                        'url': str(row.get('url', '')),
                        'image_path': str(row.get('image_path', row.get('image', ''))),
                        'has_layout': False,  # æ ‡è®°ä¸ºæ— å¸ƒå±€æ•°æ®
                        'objects': []  # ç©ºå¯¹è±¡åˆ—è¡¨
                    }
                    
                    samples.append(sample)
        except Exception as e:
            print(f"âš ï¸ å¤„ç†æ–‡ä»¶ {csv_file} æ—¶å‡ºé”™: {e}")
            continue
    
    print(f"âœ“ æŠ½å–äº† {len(samples)} æ¡é€šç”¨æ•°æ®")
    return samples


def create_mixed_dataset(layout_samples: List[Dict], general_samples: List[Dict],
                         layout_ratio: float = 0.3) -> List[Dict]:
    """
    åˆ›å»ºæ··åˆæ•°æ®é›†
    
    Args:
        layout_samples: å¸¦å¸ƒå±€çš„é»„é‡‘æ•°æ®
        general_samples: é€šç”¨æ•°æ®ï¼ˆæ— å¸ƒå±€ï¼‰
        layout_ratio: Layout æ•°æ®åœ¨ batch ä¸­çš„æ¯”ä¾‹ï¼ˆä¾‹å¦‚ 0.3 è¡¨ç¤º 30% Layout, 70% Generalï¼‰
    
    Returns:
        æ··åˆåçš„æ•°æ®é›†
    """
    # æ ‡è®°æ•°æ®æ¥æº
    for sample in layout_samples:
        sample['has_layout'] = True
        sample['data_source'] = 'layout_golden'
    
    for sample in general_samples:
        sample['has_layout'] = False
        sample['data_source'] = 'general_wukong'
    
    # è®¡ç®—æ··åˆæ¯”ä¾‹
    total_layout = len(layout_samples)
    # æ ¹æ® layout_ratio è®¡ç®—éœ€è¦çš„ general æ•°æ®é‡
    # layout_ratio = layout / (layout + general)
    # general = layout * (1 - layout_ratio) / layout_ratio
    if layout_ratio > 0:
        target_general = int(total_layout * (1 - layout_ratio) / layout_ratio)
    else:
        target_general = len(general_samples)
    
    # å¦‚æœ general æ•°æ®ä¸å¤Ÿï¼Œä½¿ç”¨å…¨éƒ¨
    if len(general_samples) < target_general:
        target_general = len(general_samples)
        print(f"âš ï¸ é€šç”¨æ•°æ®ä¸è¶³ï¼Œä½¿ç”¨å…¨éƒ¨ {len(general_samples)} æ¡")
    
    # éšæœºé‡‡æ · general æ•°æ®
    selected_general = random.sample(general_samples, min(target_general, len(general_samples)))
    
    # åˆå¹¶
    mixed_samples = layout_samples + selected_general
    
    # æ‰“ä¹±é¡ºåº
    random.shuffle(mixed_samples)
    
    # æ·»åŠ æ··åˆä¿¡æ¯
    for i, sample in enumerate(mixed_samples):
        sample['mixed_id'] = i
        sample['is_layout'] = sample.get('has_layout', False)
    
    return mixed_samples


def main():
    parser = argparse.ArgumentParser(description="å‡†å¤‡æ··åˆè®­ç»ƒæ•°æ®")
    parser.add_argument(
        "--layout-data",
        type=str,
        required=True,
        help="å¸¦å¸ƒå±€çš„é»„é‡‘æ•°æ® JSONL æ–‡ä»¶",
    )
    parser.add_argument(
        "--general-data",
        type=str,
        required=True,
        help="Wukong æ•°æ®ç›®å½•æˆ–æ–‡ä»¶ï¼ˆç”¨äºæŠ½å–é€šç”¨æ•°æ®ï¼‰",
    )
    parser.add_argument(
        "--output-jsonl",
        type=str,
        required=True,
        help="è¾“å‡ºçš„æ··åˆæ•°æ®é›† JSONL æ–‡ä»¶",
    )
    parser.add_argument(
        "--layout-ratio",
        type=float,
        default=0.3,
        help="Layout æ•°æ®åœ¨æ··åˆæ•°æ®é›†ä¸­çš„æ¯”ä¾‹ï¼ˆ0.3 è¡¨ç¤º 30% Layout, 70% Generalï¼‰",
    )
    parser.add_argument(
        "--general-count",
        type=int,
        default=50000,
        help="ä» Wukong ä¸­æŠ½å–çš„é€šç”¨æ•°æ®æ•°é‡",
    )
    parser.add_argument(
        "--seed",
        type=int,
        default=42,
        help="éšæœºç§å­",
    )
    args = parser.parse_args()
    
    random.seed(args.seed)
    
    print("=" * 60)
    print("ğŸ”„ å‡†å¤‡æ··åˆè®­ç»ƒæ•°æ®")
    print("=" * 60)
    print(f"Layout æ•°æ®: {args.layout_data}")
    print(f"é€šç”¨æ•°æ®æº: {args.general_data}")
    print(f"Layout æ¯”ä¾‹: {args.layout_ratio}")
    print(f"é€šç”¨æ•°æ®é‡: {args.general_count}")
    print()
    
    # 1. åŠ è½½ Layout æ•°æ®
    print("ğŸ“¥ Step 1: åŠ è½½ Layout æ•°æ®...")
    layout_samples = load_layout_data(args.layout_data)
    print(f"âœ“ åŠ è½½ {len(layout_samples)} æ¡ Layout æ•°æ®")
    
    # 2. åŠ è½½é€šç”¨æ•°æ®
    print(f"\nğŸ“¥ Step 2: ä» Wukong æŠ½å–é€šç”¨æ•°æ®...")
    general_samples = load_general_data(args.general_data, args.general_count)
    print(f"âœ“ æŠ½å– {len(general_samples)} æ¡é€šç”¨æ•°æ®")
    
    # 3. åˆ›å»ºæ··åˆæ•°æ®é›†
    print(f"\nğŸ”„ Step 3: åˆ›å»ºæ··åˆæ•°æ®é›†...")
    mixed_samples = create_mixed_dataset(
        layout_samples,
        general_samples,
        args.layout_ratio
    )
    
    # ç»Ÿè®¡
    layout_count = sum(1 for s in mixed_samples if s.get('has_layout', False))
    general_count = len(mixed_samples) - layout_count
    
    print(f"âœ“ æ··åˆå®Œæˆ:")
    print(f"  - Layout æ•°æ®: {layout_count} æ¡ ({layout_count/len(mixed_samples)*100:.1f}%)")
    print(f"  - é€šç”¨æ•°æ®: {general_count} æ¡ ({general_count/len(mixed_samples)*100:.1f}%)")
    print(f"  - æ€»è®¡: {len(mixed_samples)} æ¡")
    
    # 4. ä¿å­˜
    print(f"\nğŸ’¾ Step 4: ä¿å­˜æ··åˆæ•°æ®é›†...")
    os.makedirs(os.path.dirname(args.output_jsonl) if os.path.dirname(args.output_jsonl) else '.', exist_ok=True)
    
    with open(args.output_jsonl, 'w', encoding='utf-8') as f:
        for sample in mixed_samples:
            f.write(json.dumps(sample, ensure_ascii=False) + '\n')
    
    print(f"âœ… æ··åˆæ•°æ®é›†å·²ä¿å­˜: {args.output_jsonl}")
    print()
    print("ğŸ’¡ æç¤º: åœ¨è®­ç»ƒæ—¶ï¼Œå¯ä»¥æ ¹æ® 'has_layout' å­—æ®µå†³å®šæ˜¯å¦ä½¿ç”¨å¸ƒå±€æ§åˆ¶")


if __name__ == "__main__":
    main()

