#!/usr/bin/env python3
"""
å‡†å¤‡åé¦ˆéªŒè¯æ•°æ®é›†

ç”Ÿæˆä¸€æ‰¹æµ‹è¯•å›¾åƒï¼ˆä½¿ç”¨å½“å‰æ¨¡å‹ï¼‰ï¼Œç„¶åä½¿ç”¨ Qwen-VL æˆ– GPT-4V éªŒè¯ä½ç½®å‡†ç¡®æ€§ï¼Œ
æ„å»º (ç”Ÿæˆå›¾åƒ, åŸå§‹prompt, éªŒè¯ç»“æœ, ä¿®æ­£prompt) å››å…ƒç»„ã€‚

Usage:
    python scripts/prepare_feedback_dataset.py \
        --model-path checkpoints/gill_opt/ \
        --prompts-file data/test_prompts.txt \
        --output-jsonl data/feedback_dataset.jsonl \
        --num-samples 1000
"""

import argparse
import json
import os
from typing import Dict, List
from tqdm import tqdm
from PIL import Image
import torch

from gill import models
from gill import feedback_verifier


def generate_test_images(gill_model, prompts: List[str], output_dir: str) -> List[str]:
    """
    ä½¿ç”¨ GILL æ¨¡å‹ç”Ÿæˆæµ‹è¯•å›¾åƒ
    
    Args:
        gill_model: GILL æ¨¡å‹å®ä¾‹
        prompts: prompt åˆ—è¡¨
        output_dir: è¾“å‡ºç›®å½•
    
    Returns:
        image_paths: ç”Ÿæˆçš„å›¾åƒè·¯å¾„åˆ—è¡¨
    """
    os.makedirs(output_dir, exist_ok=True)
    
    image_paths = []
    for i, prompt in enumerate(tqdm(prompts, desc="ç”Ÿæˆå›¾åƒ")):
        try:
            # ç”Ÿæˆå›¾åƒï¼ˆå¸¦å¸ƒå±€æ§åˆ¶ï¼‰
            outputs = gill_model.generate_for_images_and_texts(
                prompts=[prompt],
                num_words=32,
                min_word_tokens=5,
                ret_scale_factor=1.0,
                gen_scale_factor=1.0,
                max_num_rets=1
            )
            
            # æå–ç”Ÿæˆçš„å›¾åƒ
            for output in outputs:
                if isinstance(output, dict) and 'gen' in output:
                    gen_images = output['gen']
                    if gen_images:
                        # ä¿å­˜ç¬¬ä¸€å¼ ç”Ÿæˆçš„å›¾åƒ
                        image = gen_images[0][0] if isinstance(gen_images[0], tuple) else gen_images[0]
                        image_path = os.path.join(output_dir, f"gen_{i:05d}.png")
                        image.save(image_path)
                        image_paths.append(image_path)
                        break
        except Exception as e:
            print(f"âš ï¸ ç”Ÿæˆå›¾åƒ {i} å¤±è´¥: {e}")
            continue
    
    return image_paths


def verify_images(verifier, image_paths: List[str], prompts: List[str],
                  expected_layouts: List[List[Dict]] = None) -> List[Dict]:
    """
    éªŒè¯ç”Ÿæˆçš„å›¾åƒ
    
    Args:
        verifier: FeedbackVerifier å®ä¾‹
        image_paths: å›¾åƒè·¯å¾„åˆ—è¡¨
        prompts: å¯¹åº”çš„ prompt åˆ—è¡¨
        expected_layouts: æœŸæœ›çš„å¸ƒå±€åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
    
    Returns:
        verification_results: éªŒè¯ç»“æœåˆ—è¡¨
    """
    results = []
    
    for image_path, prompt in tqdm(zip(image_paths, prompts), 
                                   total=len(image_paths), 
                                   desc="éªŒè¯å›¾åƒ"):
        try:
            image = Image.open(image_path).convert('RGB')
            expected_layout = expected_layouts[image_paths.index(image_path)] if expected_layouts else None
            
            result = verifier.verify(image, prompt, expected_layout)
            result['image_path'] = image_path
            result['original_prompt'] = prompt
            results.append(result)
        except Exception as e:
            print(f"âš ï¸ éªŒè¯å›¾åƒ {image_path} å¤±è´¥: {e}")
            results.append({
                "correct": False,
                "confidence": 0.0,
                "feedback": f"éªŒè¯å¤±è´¥: {str(e)}",
                "suggested_prompt": prompt,
                "image_path": image_path,
                "original_prompt": prompt
            })
    
    return results


def create_feedback_dataset(model_path: str,
                           prompts_file: str,
                           output_jsonl: str,
                           num_samples: int = 1000,
                           output_image_dir: str = "feedback_images"):
    """
    åˆ›å»ºåé¦ˆæ•°æ®é›†
    
    Args:
        model_path: GILL æ¨¡å‹è·¯å¾„
        prompts_file: prompt æ–‡ä»¶è·¯å¾„ï¼ˆæ¯è¡Œä¸€ä¸ª promptï¼‰
        output_jsonl: è¾“å‡º JSONL æ–‡ä»¶è·¯å¾„
        num_samples: æ ·æœ¬æ•°é‡
        output_image_dir: ç”Ÿæˆçš„å›¾åƒä¿å­˜ç›®å½•
    """
    # 1. åŠ è½½æ¨¡å‹
    print(f"ğŸ“¦ åŠ è½½ GILL æ¨¡å‹: {model_path}")
    gill_model = models.load_gill(model_path, load_ret_embs=False, load_sd=True)
    gill_model.eval()
    
    # 2. åŠ è½½ prompts
    print(f"ğŸ“– è¯»å– prompts: {prompts_file}")
    with open(prompts_file, 'r', encoding='utf-8') as f:
        prompts = [line.strip() for line in f if line.strip()][:num_samples]
    
    print(f"âœ“ å…± {len(prompts)} ä¸ª prompts")
    
    # 3. ç”Ÿæˆæµ‹è¯•å›¾åƒ
    print(f"\nğŸ¨ ç”Ÿæˆæµ‹è¯•å›¾åƒ...")
    image_paths = generate_test_images(gill_model, prompts, output_image_dir)
    print(f"âœ“ ç”Ÿæˆ {len(image_paths)} å¼ å›¾åƒ")
    
    # 4. éªŒè¯å›¾åƒ
    print(f"\nğŸ” éªŒè¯å›¾åƒ...")
    verifier = feedback_verifier.create_feedback_verifier()
    verification_results = verify_images(verifier, image_paths, prompts)
    
    # 5. ä¿å­˜ç»“æœ
    print(f"\nğŸ’¾ ä¿å­˜åé¦ˆæ•°æ®é›†: {output_jsonl}")
    with open(output_jsonl, 'w', encoding='utf-8') as f:
        for result in verification_results:
            f.write(json.dumps(result, ensure_ascii=False) + '\n')
    
    # ç»Ÿè®¡ä¿¡æ¯
    correct_count = sum(1 for r in verification_results if r.get("correct", False))
    print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"  æ€»æ ·æœ¬æ•°: {len(verification_results)}")
    print(f"  é€šè¿‡éªŒè¯: {correct_count} ({correct_count/len(verification_results)*100:.1f}%)")
    print(f"  æœªé€šè¿‡éªŒè¯: {len(verification_results) - correct_count}")
    
    print(f"âœ“ å®Œæˆï¼")


def main():
    parser = argparse.ArgumentParser(description="å‡†å¤‡åé¦ˆéªŒè¯æ•°æ®é›†")
    parser.add_argument('--model-path', type=str, required=True,
                       help='GILL æ¨¡å‹è·¯å¾„')
    parser.add_argument('--prompts-file', type=str, required=True,
                       help='Prompt æ–‡ä»¶è·¯å¾„ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰')
    parser.add_argument('--output-jsonl', type=str, required=True,
                       help='è¾“å‡º JSONL æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--num-samples', type=int, default=1000,
                       help='æ ·æœ¬æ•°é‡')
    parser.add_argument('--output-image-dir', type=str, default='feedback_images',
                       help='ç”Ÿæˆçš„å›¾åƒä¿å­˜ç›®å½•')
    
    args = parser.parse_args()
    
    create_feedback_dataset(
        args.model_path,
        args.prompts_file,
        args.output_jsonl,
        args.num_samples,
        args.output_image_dir
    )


if __name__ == '__main__':
    main()

