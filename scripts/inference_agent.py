#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ¨ç†ä»£ç†è„šæœ¬ (Inference Agent)
å®ç°å®Œæ•´çš„"ç”Ÿæˆ-éªŒè¯-ä¿®æ”¹"é—­ç¯é“¾è·¯

æ ¸å¿ƒæµç¨‹ï¼š
1. User Prompt â†’ Layout Planner (ç”Ÿæˆå¸ƒå±€)
2. Layout â†’ Spatial Adapter â†’ Image Generation (ç”Ÿæˆå›¾åƒ)
3. Image â†’ Feedback Verifier (éªŒè¯)
4. å¦‚æœå¤±è´¥ â†’ åé¦ˆç»™ Layout Planner â†’ é‡æ–°ç”Ÿæˆ
5. é‡å¤ç›´åˆ°æˆåŠŸæˆ–è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°

è¿™æ˜¯å°†é¡¹ç›®ä»"å·¥ç¨‹å¤ç°"æå‡åˆ°"ç®—æ³•åˆ›æ–°"çš„å…³é”®æ¨¡å—ã€‚
"""

import argparse
import os
import torch
from PIL import Image
from typing import Dict, List, Optional
import json
from pathlib import Path

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from gill.models import GILL, GILLArgs
from gill.layout_planner import LayoutPlanner, create_layout_planner_from_gill
from gill.feedback_verifier import FeedbackVerifier, create_feedback_verifier
from gill.spatial_adapter import create_spatial_adapter_for_kolors, load_spatial_adapter_state_dict


class InferenceAgent:
    """
    æ¨ç†ä»£ç†ï¼šå®ç°ç”Ÿæˆ-éªŒè¯-ä¿®æ”¹é—­ç¯
    """
    
    def __init__(
        self,
        gill_model_path: Optional[str] = None,
        layout_planner_path: Optional[str] = None,
        spatial_adapter_path: Optional[str] = None,
        verifier_model_path: str = "/mnt/disk/lxh/models/Qwen2.5-VL-7B-Instruct",
        verifier_type: str = "hybrid",  # æ·»åŠ  verifier_type å‚æ•°
        device: str = "cuda",
        max_retries: int = 3,
        enable_cot: bool = True  # Chain-of-Thought
    ):
        """
        Args:
            gill_model_path: GILL æ¨¡å‹è·¯å¾„ï¼ˆå¯é€‰ï¼Œå¦‚æœä½¿ç”¨ Kolors å¯ç›´æ¥ç”¨ Kolorsï¼‰
            layout_planner_path: Layout Planner æ¨¡å‹è·¯å¾„
            spatial_adapter_path: Spatial Adapter æ¨¡å‹è·¯å¾„
            verifier_model_path: éªŒè¯å™¨æ¨¡å‹è·¯å¾„ï¼ˆQwen2-VLï¼‰
            device: è®¾å¤‡
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            enable_cot: æ˜¯å¦å¯ç”¨ Chain-of-Thoughtï¼ˆæ€è€ƒè¿‡ç¨‹ï¼‰
        """
        self.device = device
        self.max_retries = max_retries
        self.enable_cot = enable_cot
        self.verifier_type = verifier_type  # ä¿å­˜ verifier_type
        
        print("ğŸš€ åˆå§‹åŒ–æ¨ç†ä»£ç†...")
        
        # 1. åŠ è½½ GILL/Kolors æ¨¡å‹
        self._load_gill_model(gill_model_path)
        
        # 2. åŠ è½½ Layout Planner
        self._load_layout_planner(layout_planner_path)
        
        # 3. åŠ è½½ Spatial Adapter
        self._load_spatial_adapter(spatial_adapter_path)
        
        # 4. åŠ è½½ Feedback Verifierï¼ˆå¼‚æ„éªŒè¯å™¨ï¼‰
        self._load_verifier(verifier_model_path, verifier_type=verifier_type)
        
        print("âœ… æ¨ç†ä»£ç†åˆå§‹åŒ–å®Œæˆï¼")
    
    def _load_gill_model(self, model_path: Optional[str]):
        """åŠ è½½ GILL/Kolors æ¨¡å‹"""
        print("ğŸ“¦ åŠ è½½ GILL/Kolors æ¨¡å‹...")
        try:
            # å¦‚æœæä¾›äº†æ¨¡å‹è·¯å¾„ï¼ŒåŠ è½½ GILL
            # å¦åˆ™ä½¿ç”¨ Kolorsï¼ˆé€šè¿‡ GILL çš„ is_kolors æ¨¡å¼ï¼‰
            model_args = GILLArgs()
            self.gill_model = GILL(
                tokenizer=None,  # Kolors æ¨¡å¼ä¸‹ä¸éœ€è¦
                model_args=model_args,
                load_sd=True,  # åŠ è½½ SDXL/Kolors
                device_map=self.device
            )
            print("  âœ… GILL/Kolors æ¨¡å‹åŠ è½½å®Œæˆ")
        except Exception as e:
            print(f"  âš ï¸ GILL æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("  â„¹ï¸ å°†å°è¯•ä½¿ç”¨ Kolors ç›´æ¥ç”Ÿæˆ")
            self.gill_model = None
    
    def _load_layout_planner(self, model_path: Optional[str]):
        """åŠ è½½ Layout Planner"""
        print("ğŸ“¦ åŠ è½½ Layout Planner...")
        if model_path and os.path.exists(model_path):
            try:
                adapter_config = os.path.join(model_path, "adapter_config.json")
                if os.path.isdir(model_path) and os.path.exists(adapter_config):
                    # LoRA/PEFT é€‚é…å™¨
                    try:
                        from peft import PeftConfig, PeftModel
                        peft_config = PeftConfig.from_pretrained(model_path)
                        base_model_path = peft_config.base_model_name_or_path
                        self.layout_planner = LayoutPlanner(
                            base_model_path,
                            device=self.device,
                            use_lora=False
                        )
                        self.layout_planner.model = PeftModel.from_pretrained(
                            self.layout_planner.model,
                            model_path
                        )
                        self.layout_planner.model.eval()
                        print("  âœ… Layout Planner (LoRA) åŠ è½½å®Œæˆ")
                    except Exception as e:
                        print(f"  âš ï¸ LoRA é€‚é…å™¨åŠ è½½å¤±è´¥: {e}")
                        self.layout_planner = None
                else:
                    # å®Œæ•´æ¨¡å‹ç›®å½•æˆ–å•ä¸€æ¨¡å‹è·¯å¾„
                    self.layout_planner = LayoutPlanner(
                        model_path,
                        device=self.device,
                        use_lora=False
                    )
                    print("  âœ… Layout Planner åŠ è½½å®Œæˆ")
            except Exception as e:
                print(f"  âš ï¸ Layout Planner åŠ è½½å¤±è´¥: {e}")
                self.layout_planner = None
        else:
            # å¦‚æœæ²¡æœ‰æä¾›è·¯å¾„ï¼Œåˆ›å»ºä¸€ä¸ªåŸºç¡€çš„ Layout Planner
            # å®é™…ä½¿ç”¨æ—¶åº”è¯¥åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
            print("  âš ï¸ æœªæä¾› Layout Planner è·¯å¾„ï¼Œå°†ä½¿ç”¨åŸºç¡€ç‰ˆæœ¬")
            self.layout_planner = None
    
    def _load_spatial_adapter(self, model_path: Optional[str]):
        """åŠ è½½ Spatial Adapter"""
        print("ğŸ“¦ åŠ è½½ Spatial Adapter...")
        self.spatial_adapter = create_spatial_adapter_for_kolors()
        if model_path and os.path.exists(model_path):
            try:
                checkpoint = torch.load(model_path, map_location=self.device)
                state_dict = checkpoint.get("state_dict", checkpoint) if isinstance(checkpoint, dict) else checkpoint
                if isinstance(state_dict, dict) and any(k.startswith("module.") for k in state_dict.keys()):
                    state_dict = {k[7:]: v for k, v in state_dict.items()}
                self.spatial_adapter = load_spatial_adapter_state_dict(
                    state_dict,
                    device=self.device,
                    dtype=torch.float32
                )
                print(f"  âœ… Spatial Adapter æƒé‡å·²è½½å…¥ (æ¨¡å—æ•°: {len(self.spatial_adapter)})")
            except Exception as e:
                print(f"  âš ï¸ Spatial Adapter åŠ è½½å¤±è´¥: {e}")
        else:
            print("  âš ï¸ æœªæä¾› Spatial Adapter è·¯å¾„ï¼Œå°†ä½¿ç”¨é»˜è®¤ç‰ˆæœ¬")
    
    def _load_verifier(self, model_path: str, verifier_type: str = "hybrid"):
        """
        åŠ è½½ Feedback Verifierï¼ˆå¼‚æ„éªŒè¯å™¨ï¼‰
        
        Args:
            model_path: æ¨¡å‹è·¯å¾„ï¼ˆç”¨äºå…¼å®¹æ—§ä»£ç ï¼‰
            verifier_type: éªŒè¯å™¨ç±»å‹
                - "hybrid": æ··åˆæ¨¡å¼ï¼ˆGrounding DINO + Qwen2-VL-7Bï¼Œæ¨èï¼‰
                - "grounding_dino": ä»…ä½¿ç”¨ Grounding DINO
                - "qwen2vl_7b": ä»…ä½¿ç”¨ Qwen2-VL-7B
        """
        print(f"ğŸ“¦ åŠ è½½ Feedback Verifier (ç±»å‹: {verifier_type})...")
        try:
            if verifier_type == "hybrid":
                # ğŸŒŸ æ¨èï¼šæ··åˆéªŒè¯å™¨ï¼ˆé¿å…è‡ªå¾ªç¯éªŒè¯åå·®ï¼‰
                self.verifier = create_feedback_verifier(
                    verifier_type="hybrid",
                    device=self.device,
                    use_grounding=True
                )
            elif verifier_type == "qwen2vl_7b":
                # ä»…ä½¿ç”¨ Qwen2-VL-7Bï¼ˆè½»é‡çº§ï¼‰
                self.verifier = create_feedback_verifier(
                    verifier_type="qwen2vl_7b",
                    device=self.device,
                    use_grounding=True
                )
            else:
                # å…¼å®¹æ—§ä»£ç 
                self.verifier = create_feedback_verifier(
                    verifier_type="qwen2vl",
                    vlm_model_name=model_path,
                    device=self.device,
                    use_grounding=True
                )
            print("  âœ… Feedback Verifier åŠ è½½å®Œæˆ")
        except Exception as e:
            print(f"  âš ï¸ Feedback Verifier åŠ è½½å¤±è´¥: {e}")
            self.verifier = None
    
    def generate_with_feedback_loop(
        self,
        prompt: str,
        guidance_scale: float = 7.5,
        num_inference_steps: int = 50,
        save_intermediate: bool = True,
        output_dir: str = "./outputs"
    ) -> Dict:
        """
        æ‰§è¡Œç”Ÿæˆ-éªŒè¯-ä¿®æ”¹é—­ç¯
        
        Args:
            prompt: ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬æç¤º
            guidance_scale: å¼•å¯¼å¼ºåº¦
            num_inference_steps: æ¨ç†æ­¥æ•°
            save_intermediate: æ˜¯å¦ä¿å­˜ä¸­é—´ç»“æœ
            output_dir: è¾“å‡ºç›®å½•
        
        Returns:
            {
                "final_image": Image,
                "layout_history": List[Dict],  # å¸ƒå±€å†å²
                "feedback_history": List[Dict],  # åé¦ˆå†å²
                "success": bool,
                "num_attempts": int
            }
        """
        os.makedirs(output_dir, exist_ok=True)
        
        print(f"\n{'='*60}")
        print(f"ğŸ¨ å¼€å§‹ç”Ÿæˆ: {prompt}")
        print(f"{'='*60}\n")
        
        layout_history = []
        feedback_history = []
        image_history = []
        
        for attempt in range(self.max_retries + 1):
            print(f"\nğŸ”„ å°è¯• {attempt + 1}/{self.max_retries + 1}")
            print("-" * 60)
            
            # Step 1: Layout Planningï¼ˆå¸¦ CoTï¼‰
            print("ğŸ“ Step 1: å¸ƒå±€è§„åˆ’...")
            layout_result = self._plan_layout(prompt, attempt, feedback_history)
            layout_history.append(layout_result)
            
            if layout_result.get("objects") is None or len(layout_result["objects"]) == 0:
                print("  âš ï¸ å¸ƒå±€è§„åˆ’å¤±è´¥ï¼Œè·³è¿‡æœ¬æ¬¡å°è¯•")
                continue
            
            print(f"  âœ… è§„åˆ’äº† {len(layout_result['objects'])} ä¸ªå¯¹è±¡")
            for obj in layout_result["objects"]:
                print(f"     - {obj['name']}: {obj['bbox']}")
            
            # Step 2: Image Generation
            print("\nğŸ¨ Step 2: å›¾åƒç”Ÿæˆ...")
            generated_image = self._generate_image(
                prompt=prompt,
                layout=layout_result,
                guidance_scale=guidance_scale,
                num_inference_steps=num_inference_steps
            )
            
            if generated_image is None:
                print("  âš ï¸ å›¾åƒç”Ÿæˆå¤±è´¥ï¼Œè·³è¿‡æœ¬æ¬¡å°è¯•")
                continue
            
            image_history.append(generated_image)
            
            # ä¿å­˜ä¸­é—´ç»“æœ
            if save_intermediate:
                intermediate_path = os.path.join(
                    output_dir,
                    f"attempt_{attempt + 1}_layout_{len(layout_result['objects'])}_objects.png"
                )
                generated_image.save(intermediate_path)
                print(f"  ğŸ’¾ å·²ä¿å­˜: {intermediate_path}")
            
            # Step 3: Verification
            print("\nğŸ” Step 3: éªŒè¯ç”Ÿæˆç»“æœ...")
            feedback = self._verify_image(
                image=generated_image,
                prompt=prompt,
                expected_layout=layout_result.get("objects")
            )
            feedback_history.append(feedback)
            
            print(f"  {'âœ…' if feedback.get('correct') else 'âŒ'} éªŒè¯ç»“æœ: {feedback.get('feedback', '')[:100]}")
            
            # Step 4: åˆ¤æ–­æ˜¯å¦éœ€è¦é‡è¯•
            if feedback.get("correct", False):
                print(f"\nğŸ‰ ç”ŸæˆæˆåŠŸï¼å…±å°è¯• {attempt + 1} æ¬¡")
                return {
                    "final_image": generated_image,
                    "layout_history": layout_history,
                    "feedback_history": feedback_history,
                    "image_history": image_history,
                    "success": True,
                    "num_attempts": attempt + 1,
                    "final_layout": layout_result
                }
            else:
                if attempt < self.max_retries:
                    refinement = feedback.get("refinement_instruction", "")
                    print(f"\n  ğŸ’¡ ä¿®æ­£å»ºè®®: {refinement[:200]}")
                    print(f"  ğŸ”„ å°†æ ¹æ®åé¦ˆè°ƒæ•´å¸ƒå±€å¹¶é‡è¯•...")
                else:
                    print(f"\nâš ï¸ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({self.max_retries + 1})ï¼Œåœæ­¢ç”Ÿæˆ")
        
        # æ‰€æœ‰å°è¯•éƒ½å¤±è´¥
        return {
            "final_image": image_history[-1] if image_history else None,
            "layout_history": layout_history,
            "feedback_history": feedback_history,
            "image_history": image_history,
            "success": False,
            "num_attempts": self.max_retries + 1,
            "final_layout": layout_history[-1] if layout_history else None
        }
    
    def _plan_layout(
        self,
        prompt: str,
        attempt: int,
        feedback_history: List[Dict]
    ) -> Dict:
        """
        å¸ƒå±€è§„åˆ’ï¼ˆæ”¯æŒåé¦ˆä¿®æ­£ï¼‰
        
        è¿™æ˜¯é—­ç¯çš„æ ¸å¿ƒï¼šæ ¹æ®éªŒè¯åé¦ˆä¿®æ­£å¸ƒå±€
        """
        if self.layout_planner is None:
            # å¦‚æœæ²¡æœ‰ Layout Plannerï¼Œè¿”å›ç©ºå¸ƒå±€
            return {"objects": [], "layout_text": ""}
        
        # ğŸŒŸ å…³é”®é€»è¾‘ï¼šæ„å»ºå¸¦åé¦ˆçš„ prompt
        current_prompt = prompt
        feedback_text = None
        
        if attempt > 0 and feedback_history:
            last_feedback = feedback_history[-1]
            
            # ä¼˜å…ˆä½¿ç”¨ refinement_instructionï¼ˆç»“æ„åŒ–åé¦ˆï¼‰
            refinement = last_feedback.get("refinement_instruction", "")
            feedback_raw = last_feedback.get("feedback", "")
            
            if refinement:
                # ä½¿ç”¨ç»“æ„åŒ–çš„ä¿®æ­£å»ºè®®
                feedback_text = refinement
                current_prompt = f"""{prompt}

ä¸Šä¸€è½®ç”Ÿæˆç»“æœå­˜åœ¨é—®é¢˜ï¼š
{refinement}

è¯·æ ¹æ®ä»¥ä¸Šåé¦ˆé‡æ–°è§„åˆ’å¸ƒå±€ï¼Œç¡®ä¿ä¿®æ­£è¿™äº›é”™è¯¯ã€‚"""
            elif feedback_raw and "ä¸ç¬¦åˆ" in feedback_raw:
                # å¦‚æœæ²¡æœ‰ç»“æ„åŒ–åé¦ˆï¼Œä½¿ç”¨åŸå§‹åé¦ˆæ–‡æœ¬
                feedback_text = feedback_raw
                current_prompt = f"""{prompt}

ä¸Šä¸€è½®éªŒè¯åé¦ˆï¼š
{feedback_raw}

è¯·åˆ†æåé¦ˆä¸­çš„é—®é¢˜ï¼Œå¹¶é‡æ–°è§„åˆ’å¸ƒå±€ä»¥ä¿®æ­£é”™è¯¯ã€‚"""
        
        # ğŸŒŸ Chain-of-Thought: å¦‚æœå¯ç”¨ï¼Œè®©æ¨¡å‹å…ˆ"æ€è€ƒ"å†è¾“å‡ºå¸ƒå±€
        enable_cot = self.enable_cot
        
        # ç”Ÿæˆå¸ƒå±€ï¼ˆä¼ é€’ feedback å‚æ•°ï¼‰
        layout_result = self.layout_planner.generate_layout(
            current_prompt,
            apply_refinement=True,
            enable_cot=enable_cot,
            feedback=feedback_text  # ä¼ é€’åé¦ˆç»™ Layout Planner
        )
        
        return layout_result
    
    def _generate_image(
        self,
        prompt: str,
        layout: Dict,
        guidance_scale: float,
        num_inference_steps: int
    ) -> Optional[Image.Image]:
        """ç”Ÿæˆå›¾åƒ"""
        if self.gill_model is None:
            print("  âš ï¸ GILL æ¨¡å‹æœªåŠ è½½ï¼Œæ— æ³•ç”Ÿæˆå›¾åƒ")
            return None
        
        try:
            # ä½¿ç”¨ GILL çš„ generate_with_layout æ–¹æ³•
            result = self.gill_model.generate_with_layout(
                prompt=prompt,
                enable_layout=True,
                enable_feedback=False,  # åœ¨ agent å±‚é¢å¤„ç†åé¦ˆ
                layout_planner=None,  # å·²ç»è§„åˆ’å¥½äº†
                spatial_adapter=self.spatial_adapter,
                feedback_verifier=None,  # åœ¨ agent å±‚é¢éªŒè¯
                guidance_scale=guidance_scale,
                num_inference_steps=num_inference_steps,
                max_retries=1  # åªç”Ÿæˆä¸€æ¬¡ï¼Œé‡è¯•åœ¨ agent å±‚é¢
            )
            
            return result.get("image")
        except Exception as e:
            print(f"  âš ï¸ å›¾åƒç”Ÿæˆå‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _verify_image(
        self,
        image: Image.Image,
        prompt: str,
        expected_layout: Optional[List[Dict]]
    ) -> Dict:
        """éªŒè¯å›¾åƒ"""
        if self.verifier is None:
            # å¦‚æœæ²¡æœ‰éªŒè¯å™¨ï¼Œé»˜è®¤é€šè¿‡
            return {
                "correct": True,
                "confidence": 0.5,
                "feedback": "éªŒè¯å™¨æœªåŠ è½½ï¼Œè·³è¿‡éªŒè¯"
            }
        
        return self.verifier.verify(
            image=image,
            original_prompt=prompt,
            expected_layout=expected_layout,
            threshold=0.7
        )


def main():
    parser = argparse.ArgumentParser(
        description="æ¨ç†ä»£ç†ï¼šå®ç°ç”Ÿæˆ-éªŒè¯-ä¿®æ”¹é—­ç¯"
    )
    parser.add_argument(
        "--prompt",
        type=str,
        required=True,
        help="è¾“å…¥æç¤ºè¯"
    )
    parser.add_argument(
        "--layout_planner_path",
        type=str,
        default=None,
        help="Layout Planner æ¨¡å‹è·¯å¾„"
    )
    parser.add_argument(
        "--spatial_adapter_path",
        type=str,
        default=None,
        help="Spatial Adapter æ¨¡å‹è·¯å¾„"
    )
    parser.add_argument(
        "--verifier_model_path",
        type=str,
        default="/mnt/disk/lxh/models/Qwen2.5-VL-7B-Instruct",
        help="éªŒè¯å™¨æ¨¡å‹è·¯å¾„ï¼ˆQwen2.5-VL-7B-Instructï¼‰"
    )
    parser.add_argument(
        "--output_dir",
        type=str,
        default="./outputs",
        help="è¾“å‡ºç›®å½•"
    )
    parser.add_argument(
        "--max_retries",
        type=int,
        default=3,
        help="æœ€å¤§é‡è¯•æ¬¡æ•°"
    )
    parser.add_argument(
        "--device",
        type=str,
        default="cuda",
        help="è®¾å¤‡"
    )
    parser.add_argument(
        "--guidance_scale",
        type=float,
        default=7.5,
        help="å¼•å¯¼å¼ºåº¦"
    )
    parser.add_argument(
        "--num_inference_steps",
        type=int,
        default=50,
        help="æ¨ç†æ­¥æ•°"
    )
    parser.add_argument(
        "--enable_cot",
        action="store_true",
        help="å¯ç”¨ Chain-of-Thoughtï¼ˆæ€è€ƒè¿‡ç¨‹ï¼‰"
    )
    
    args = parser.parse_args()
    
    # åˆ›å»ºæ¨ç†ä»£ç†
    agent = InferenceAgent(
        layout_planner_path=args.layout_planner_path,
        spatial_adapter_path=args.spatial_adapter_path,
        verifier_model_path=args.verifier_model_path,
        device=args.device,
        max_retries=args.max_retries,
        enable_cot=args.enable_cot
    )
    
    # æ‰§è¡Œç”Ÿæˆ
    result = agent.generate_with_feedback_loop(
        prompt=args.prompt,
        guidance_scale=args.guidance_scale,
        num_inference_steps=args.num_inference_steps,
        save_intermediate=True,
        output_dir=args.output_dir
    )
    
    # ä¿å­˜æœ€ç»ˆç»“æœ
    if result["success"]:
        final_path = os.path.join(args.output_dir, "final_result.png")
        result["final_image"].save(final_path)
        print(f"\nâœ… æœ€ç»ˆç»“æœå·²ä¿å­˜: {final_path}")
    else:
        print(f"\nâš ï¸ ç”Ÿæˆæœªå®Œå…¨æˆåŠŸï¼Œä½†å·²ä¿å­˜æœ€åä¸€æ¬¡å°è¯•çš„ç»“æœ")
    
    # ä¿å­˜å†å²è®°å½•
    history_path = os.path.join(args.output_dir, "generation_history.json")
    with open(history_path, "w", encoding="utf-8") as f:
        json.dump({
            "prompt": args.prompt,
            "success": result["success"],
            "num_attempts": result["num_attempts"],
            "layout_history": [
                {
                    "objects": layout.get("objects", []),
                    "layout_text": layout.get("layout_text", "")
                }
                for layout in result["layout_history"]
            ],
            "feedback_history": result["feedback_history"]
        }, f, ensure_ascii=False, indent=2)
    print(f"ğŸ“ ç”Ÿæˆå†å²å·²ä¿å­˜: {history_path}")


if __name__ == "__main__":
    main()
