#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æœ€å°å¯ç”¨çš„æœ¬åœ°æ ‡æ³¨è„šæœ¬ï¼ˆQwen2-VL-7B-Instructï¼‰
åŠŸèƒ½ï¼š
 1. è¯»å–æœªæ ‡æ³¨çš„æ‚Ÿç©º JSONLï¼ˆæ¯è¡Œè‡³å°‘åŒ…å« image_path, captionï¼‰
 2. è¿‡æ»¤åå›¾ï¼ˆä¸å­˜åœ¨/è¿‡å°ï¼‰
 3. è°ƒç”¨æœ¬åœ° Qwen2-VL-7B-Instruct ç”Ÿæˆ bboxï¼Œè¦æ±‚è¾“å‡º JSON åˆ—è¡¨
 4. å°†ç»“æœé€è¡Œå†™å…¥æ–°çš„ JSONLï¼ˆä¿ç•™åŸå­—æ®µï¼Œæ–°å¢ objectsï¼‰

ç”¨æ³•ç¤ºä¾‹ï¼š
python scripts/annotate_wukong_qwen2vl.py \
  --input /mnt/disk/lxh/Project/gill-data/wukong_raw.jsonl \
  --image-root /mnt/disk/lxh/Project/gill-data/images \
  --output /mnt/disk/lxh/Project/gill-data/wukong_labeled.jsonl \
  --model Qwen/Qwen2-VL-7B-Instruct \
  --device cuda \
  --max-samples 10000
"""

import argparse
import json
import os
import re
from typing import List, Dict, Any, Optional, Set

import torch
from PIL import Image
from transformers import AutoProcessor
from transformers import Qwen2VLForConditionalGeneration


def is_valid_image(path: str, min_size: int = 256) -> bool:
    if not os.path.exists(path):
        return False
    try:
        with Image.open(path) as img:
            w, h = img.size
            return w >= min_size and h >= min_size
    except Exception:
        return False


def build_prompt(caption: str) -> str:
    # ä»…å…³æ³¨æè¿°ä¸­æåˆ°çš„å®ä½“ï¼Œå‡å°‘èƒŒæ™¯å™ªå£°
    return (
        "æ£€æµ‹å›¾åƒä¸­ä¸æè¿°æœ€ç›¸å…³çš„ç‰©ä½“ï¼Œåªè¾“å‡ºæè¿°é‡Œå‡ºç°çš„å®ä½“ã€‚"
        "ä¸¥æ ¼è¿”å› JSON æ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ å½¢å¦‚ï¼š"
        '{"name": "ç±»åˆ«", "bbox": [x1, y1, x2, y2]}ï¼Œåæ ‡éœ€ 0-1 å½’ä¸€åŒ–ï¼›'
        "ä¸è¦æ·»åŠ é¢å¤–è§£é‡Šæˆ–æ–‡æœ¬ã€‚æè¿°ï¼š"
        f"{caption}"
    )


def parse_bboxes(text: str) -> List[Dict[str, Any]]:
    """
    å°è¯•ä»æ¨¡å‹è¾“å‡ºä¸­è§£æ JSON æ•°ç»„ï¼›è‹¥å¤±è´¥åˆ™è¿”å›ç©ºåˆ—è¡¨ã€‚
    - æ”¯æŒåŒ…å«å¤šæ®µå†…å®¹ã€markdown ä»£ç å—ã€å¤šä¸ªæ•°ç»„ç­‰æƒ…å†µ
    """
    # å»æ‰ markdown ä»£ç å—æ ‡è®°
    text = re.sub(r"```[a-zA-Z]*", "", text)
    text = text.replace("```", "")

    # å¯èƒ½å­˜åœ¨å¤šä¸ªæ•°ç»„ï¼šä¾æ¬¡å°è¯•éè´ªå©ªåŒ¹é…çš„ [ ... ]
    for m in re.finditer(r"\[.*?\]", text, re.S):
        candidate = m.group(0)
        try:
            data = json.loads(candidate)
        except Exception:
            continue

        # åªæ¥å— list ä¸”å…¶ä¸­è‡³å°‘æœ‰ä¸€ä¸ªå¸¦ bbox çš„ dict
        if isinstance(data, list):
            valid: List[Dict[str, Any]] = []
            for obj in data:
                if (
                    isinstance(obj, dict)
                    and "bbox" in obj
                    and isinstance(obj["bbox"], list)
                    and len(obj["bbox"]) == 4
                ):
                    try:
                        bbox = [float(x) for x in obj["bbox"]]
                    except Exception:
                        continue
                    valid.append(
                        {
                            "name": obj.get("name", "object"),
                            "bbox": bbox,
                        }
                    )
            if valid:
                return valid

    # å…œåº•ï¼šæœ‰æ—¶æ¨¡å‹ç›´æ¥è¾“å‡ºå•ä¸ª dict
    try:
        data = json.loads(text)
        if (
            isinstance(data, dict)
            and "bbox" in data
            and isinstance(data["bbox"], list)
            and len(data["bbox"]) == 4
        ):
            return [
                {
                    "name": data.get("name", "object"),
                    "bbox": [float(x) for x in data["bbox"]],
                }
            ]
    except Exception:
        pass

    return []


@torch.inference_mode()
def annotate_batch(
    model,
    processor,
    image_paths: List[str],
    captions: List[str],
    device: str = "cuda",
    max_new_tokens: int = 256,
) -> List[Optional[List[Dict[str, Any]]]]:
    batch_images = []
    texts = []
    for path, cap in zip(image_paths, captions):
        try:
            img = Image.open(path).convert("RGB")
        except Exception:
            batch_images.append(None)
            texts.append(None)
            continue
        prompt = build_prompt(cap)
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {"type": "image", "image": img},
                ],
            }
        ]
        text = processor.apply_chat_template(
            messages, tokenize=False, add_generation_prompt=True
        )
        batch_images.append(img)
        texts.append(text)

    # è¿‡æ»¤æ‰æŸåçš„æ ·æœ¬
    valid_idx = [i for i, t in enumerate(texts) if t is not None]
    if not valid_idx:
        return [None] * len(image_paths)

    inputs = processor(
        text=[texts[i] for i in valid_idx],
        images=[batch_images[i] for i in valid_idx],
        return_tensors="pt",
        padding=True,
    ).to(device)

    output_ids = model.generate(
        **inputs,
        max_new_tokens=max_new_tokens,
        do_sample=False,
        num_beams=1,
    )
    generated_ids = [
        out[len(inp) :] for inp, out in zip(inputs["input_ids"], output_ids)
    ]
    text_outputs = processor.batch_decode(
        generated_ids, skip_special_tokens=True
    )

    # ç®€å•è°ƒè¯•ï¼šè®°å½•å°‘é‡åŸå§‹è¾“å‡ºï¼Œä¾¿äºæ£€æŸ¥æ ¼å¼
    try:
        if not hasattr(annotate_batch, "_log_count"):
            annotate_batch._log_count = 0
        if annotate_batch._log_count < 3:
            with open("qwen_vl_debug_outputs.txt", "a", encoding="utf-8") as f:
                for t in text_outputs:
                    f.write(t)
                    f.write("\n" + "-" * 60 + "\n")
            annotate_batch._log_count += 1
    except Exception:
        pass

    parsed_results = [None] * len(image_paths)
    for idx, out in zip(valid_idx, text_outputs):
        parsed_results[idx] = parse_bboxes(out)
    return parsed_results


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--input", required=True, help="æœªæ ‡æ³¨çš„ JSONL è·¯å¾„")
    parser.add_argument("--output", required=True, help="è¾“å‡º JSONL è·¯å¾„")
    parser.add_argument("--image-root", required=True, help="å›¾ç‰‡æ ¹ç›®å½•")
    parser.add_argument(
        "--model", default="Qwen/Qwen2-VL-7B-Instruct", help="æ¨¡å‹åç§°æˆ–è·¯å¾„"
    )
    parser.add_argument("--device", default="cuda")
    parser.add_argument("--max-samples", type=int, default=None)
    parser.add_argument("--min-size", type=int, default=256)
    parser.add_argument("--batch-size", type=int, default=4)
    args = parser.parse_args()

    device = args.device
    print(f"ğŸš€ åŠ è½½æ¨¡å‹ {args.model} åˆ° {device} ...")
    model = Qwen2VLForConditionalGeneration.from_pretrained(
        args.model,
        device_map=device,
        torch_dtype="auto",
    )
    processor = AutoProcessor.from_pretrained(args.model)

    # æ–­ç‚¹ç»­ä¼ ï¼šè¯»å–å·²æœ‰è¾“å‡ºçš„ image_path é›†åˆ
    processed: Set[str] = set()
    if os.path.exists(args.output):
        with open(args.output, "r", encoding="utf-8") as fexist:
            for line in fexist:
                try:
                    obj = json.loads(line)
                    p = obj.get("image_path") or obj.get("image")
                    if p:
                        processed.add(p)
                except Exception:
                    continue
        fout_mode = "a"
        print(f"ğŸ§© æ£€æµ‹åˆ°å·²å­˜åœ¨è¾“å‡ºï¼Œè·³è¿‡ {len(processed)} æ¡ï¼Œç»§ç»­è¿½åŠ å†™å…¥ã€‚")
    else:
        fout_mode = "w"

    total, success = 0, 0
    os.makedirs(os.path.dirname(args.output), exist_ok=True)
    buffer_items = []

    with open(args.input, "r", encoding="utf-8") as fin, open(
        args.output, fout_mode, encoding="utf-8"
    ) as fout:
        for line in fin:
            if not line.strip():
                continue
            try:
                item = json.loads(line)
            except Exception:
                continue

            rel_path = item.get("image_path") or item.get("image")
            caption = item.get("caption") or ""
            if not rel_path:
                continue
            if rel_path in processed:
                continue

            full_path = rel_path
            if not os.path.isabs(full_path):
                full_path = os.path.join(args.image_root, rel_path)
            if not is_valid_image(full_path, min_size=args.min_size):
                continue

            buffer_items.append((item, full_path, rel_path, caption))
            # æ»¡æ‰¹å¤„ç†
            if len(buffer_items) >= args.batch_size:
                total += len(buffer_items)
                imgs = [x[1] for x in buffer_items]
                caps = [x[3] for x in buffer_items]
                results = annotate_batch(
                    model, processor, imgs, caps, device=device
                )
                for (itm, _, relp, _), bboxes in zip(buffer_items, results):
                    if bboxes:
                        itm["objects"] = bboxes
                        fout.write(json.dumps(itm, ensure_ascii=False) + "\n")
                        processed.add(relp)
                        success += 1
                buffer_items = []
                if args.max_samples and success >= args.max_samples:
                    break
                if success % 50 == 0:
                    print(f"âœ“ å·²æ ‡æ³¨ {success}")

        # å¤„ç†æ®‹ç•™ä¸è¶³ä¸€æ‰¹çš„æ ·æœ¬
        if buffer_items and (not args.max_samples or success < args.max_samples):
            total += len(buffer_items)
            imgs = [x[1] for x in buffer_items]
            caps = [x[3] for x in buffer_items]
            results = annotate_batch(
                model, processor, imgs, caps, device=device
            )
            for (itm, _, relp, _), bboxes in zip(buffer_items, results):
                if not bboxes:
                    continue
                # è¿‡æ»¤æ˜æ˜¾æ— æ•ˆæˆ–â€œå…¨å›¾â€æ¡†
                filtered = []
                for obj in bboxes:
                    name = str(obj.get("name", "")).lower()
                    bbox = obj.get("bbox", [])
                    if not (isinstance(bbox, list) and len(bbox) == 4):
                        continue
                    x1, y1, x2, y2 = bbox
                    # åˆ¤å®šæ˜¯å¦ä¸º 0-1 æˆ– 0-1000 åæ ‡ç³»ä¸‹çš„å…¨å›¾æ¡†
                    is_full_01 = (
                        0.0 <= x1 <= 1.0
                        and 0.0 <= y1 <= 1.0
                        and 0.0 <= x2 <= 1.0
                        and 0.0 <= y2 <= 1.0
                        and x1 == 0.0
                        and y1 == 0.0
                        and x2 == 1.0
                        and y2 == 1.0
                    )
                    is_full_1000 = (
                        0.0 <= x1 <= 1000.0
                        and 0.0 <= y1 <= 1000.0
                        and 0.0 <= x2 <= 1000.0
                        and 0.0 <= y2 <= 1000.0
                        and x1 == 0.0
                        and y1 == 0.0
                        and x2 == 1000.0
                        and y2 == 1000.0
                    )
                    # ä¸€äº›æ˜æ˜¾ç¼ºä¹è¯­ä¹‰å®šä½çš„ç±»åˆ«åï¼Œä¹Ÿç›´æ¥ä¸¢å¼ƒ
                    if name in ["å…¨å›¾", "å›¾ç‰‡", "æ–‡å­—", "ç‰©ä½“", "äººå", "æ£€æµ‹æŠ¥å‘Š"]:
                        continue
                    if is_full_01 or is_full_1000:
                        continue
                    filtered.append({"name": obj.get("name", "object"), "bbox": bbox})

                if not filtered:
                    continue
                itm["objects"] = filtered
                fout.write(json.dumps(itm, ensure_ascii=False) + "\n")
                processed.add(relp)
                success += 1
            for (itm, _, relp, _), bboxes in zip(buffer_items, results):
                if not bboxes:
                    continue
                filtered = []
                for obj in bboxes:
                    name = str(obj.get("name", "")).lower()
                    bbox = obj.get("bbox", [])
                    if not (isinstance(bbox, list) and len(bbox) == 4):
                        continue
                    x1, y1, x2, y2 = bbox
                    is_full_01 = (
                        0.0 <= x1 <= 1.0
                        and 0.0 <= y1 <= 1.0
                        and 0.0 <= x2 <= 1.0
                        and 0.0 <= y2 <= 1.0
                        and x1 == 0.0
                        and y1 == 0.0
                        and x2 == 1.0
                        and y2 == 1.0
                    )
                    is_full_1000 = (
                        0.0 <= x1 <= 1000.0
                        and 0.0 <= y1 <= 1000.0
                        and 0.0 <= x2 <= 1000.0
                        and 0.0 <= y2 <= 1000.0
                        and x1 == 0.0
                        and y1 == 0.0
                        and x2 == 1000.0
                        and y2 == 1000.0
                    )
                    if name in ["å…¨å›¾", "å›¾ç‰‡", "æ–‡å­—", "ç‰©ä½“", "äººå", "æ£€æµ‹æŠ¥å‘Š"]:
                        continue
                    if is_full_01 or is_full_1000:
                        continue
                    filtered.append({"name": obj.get("name", "object"), "bbox": bbox})

                if not filtered:
                    continue
                itm["objects"] = filtered
                fout.write(json.dumps(itm, ensure_ascii=False) + "\n")
                processed.add(relp)
                success += 1

    print(f"å®Œæˆã€‚æˆåŠŸ {success} æ¡ã€‚è¾“å‡º -> {args.output}")


if __name__ == "__main__":
    main()

