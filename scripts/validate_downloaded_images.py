#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
éªŒè¯å·²ä¸‹è½½å›¾ç‰‡çš„å®Œæ•´æ€§è„šæœ¬

åŠŸèƒ½ï¼š
1. è¯»å– JSONL æ–‡ä»¶ï¼Œè·å–æ‰€æœ‰å·²ä¸‹è½½çš„å›¾ç‰‡è·¯å¾„
2. ä½¿ç”¨ PIL éªŒè¯æ¯å¼ å›¾ç‰‡çš„å®Œæ•´æ€§
3. åˆ é™¤æŸåçš„å›¾ç‰‡ï¼Œå¹¶æ›´æ–° JSONL æ–‡ä»¶ï¼ˆç§»é™¤æŸåå›¾ç‰‡çš„è®°å½•ï¼‰

ç”¨æ³•ï¼š
python scripts/validate_downloaded_images.py \
    --input /mnt/disk/lxh/gill_data/wukong_downloaded_500k.jsonl \
    --output /mnt/disk/lxh/gill_data/wukong_downloaded_validated.jsonl
"""

import os
import json
import argparse
from pathlib import Path
from PIL import Image
from tqdm import tqdm


def validate_image_file(image_path: str) -> bool:
    """éªŒè¯å•å¼ å›¾ç‰‡çš„å®Œæ•´æ€§"""
    try:
        if not os.path.exists(image_path):
            return False
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        if os.path.getsize(image_path) < 1024:
            return False
        
        # ä½¿ç”¨ PIL éªŒè¯å›¾ç‰‡ç»“æ„
        with Image.open(image_path) as img:
            img.verify()  # éªŒè¯æ–‡ä»¶ç»“æ„
        
        # verify() åéœ€è¦é‡æ–°æ‰“å¼€æ‰èƒ½è¯»å–åƒç´ æ•°æ®
        with Image.open(image_path) as img:
            img.load()  # åŠ è½½åƒç´ æ•°æ®ï¼Œç¡®ä¿å›¾ç‰‡å®Œæ•´
        
        return True
    except Exception:
        return False


def main(args):
    """ä¸»å‡½æ•°"""
    if not os.path.exists(args.input):
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input}")
        return
    
    print(f"ğŸ“– è¯»å–è¾“å…¥æ–‡ä»¶: {args.input}")
    
    # è¯»å–æ‰€æœ‰è®°å½•
    all_records = []
    with open(args.input, 'r', encoding='utf-8') as f:
        for line in f:
            try:
                record = json.loads(line.strip())
                all_records.append(record)
            except json.JSONDecodeError:
                continue
    
    print(f"âœ… è¯»å–åˆ° {len(all_records)} æ¡è®°å½•")
    
    # éªŒè¯å›¾ç‰‡
    valid_records = []
    invalid_count = 0
    missing_count = 0
    
    print(f"\nğŸ” å¼€å§‹éªŒè¯å›¾ç‰‡å®Œæ•´æ€§...")
    for record in tqdm(all_records, desc="éªŒè¯è¿›åº¦", unit="img"):
        image_path = record.get('image_path', '')
        
        if not image_path:
            invalid_count += 1
            continue
        
        # å¤„ç†ç›¸å¯¹è·¯å¾„
        if not os.path.isabs(image_path):
            if args.image_root:
                image_path = os.path.join(args.image_root, image_path)
            else:
                # å°è¯•ä» JSONL ä¸­çš„è·¯å¾„æ¨æ–­
                pass
        
        if not os.path.exists(image_path):
            missing_count += 1
            if args.remove_missing:
                continue  # è·³è¿‡ç¼ºå¤±çš„å›¾ç‰‡
            else:
                valid_records.append(record)  # ä¿ç•™è®°å½•ï¼ˆå¯èƒ½è·¯å¾„é—®é¢˜ï¼‰
        elif validate_image_file(image_path):
            valid_records.append(record)
        else:
            # å›¾ç‰‡æŸåï¼Œåˆ é™¤æ–‡ä»¶
            invalid_count += 1
            try:
                os.remove(image_path)
                print(f"  ğŸ—‘ï¸  åˆ é™¤æŸåå›¾ç‰‡: {os.path.basename(image_path)}")
            except Exception as e:
                print(f"  âš ï¸  åˆ é™¤å¤±è´¥ {image_path}: {e}")
    
    # å†™å…¥éªŒè¯åçš„è®°å½•
    print(f"\nğŸ’¾ å†™å…¥éªŒè¯åçš„è®°å½•åˆ°: {args.output}")
    with open(args.output, 'w', encoding='utf-8') as f:
        for record in valid_records:
            f.write(json.dumps(record, ensure_ascii=False) + "\n")
    
    # è¾“å‡ºç»Ÿè®¡
    print(f"\n{'='*60}")
    print(f"ğŸ“Š éªŒè¯å®Œæˆç»Ÿè®¡")
    print(f"{'='*60}")
    print(f"æ€»è®°å½•æ•°: {len(all_records)}")
    print(f"æœ‰æ•ˆå›¾ç‰‡: {len(valid_records)}")
    print(f"æŸåå›¾ç‰‡: {invalid_count}")
    print(f"ç¼ºå¤±å›¾ç‰‡: {missing_count}")
    if len(all_records) > 0:
        valid_rate = (len(valid_records) / len(all_records)) * 100
        print(f"æœ‰æ•ˆç‡: {valid_rate:.2f}%")
    print(f"{'='*60}")
    
    if args.backup_original and args.input != args.output:
        import shutil
        backup_path = args.input + ".backup"
        print(f"\nğŸ’¾ å¤‡ä»½åŸæ–‡ä»¶åˆ°: {backup_path}")
        shutil.copy2(args.input, backup_path)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="éªŒè¯å·²ä¸‹è½½å›¾ç‰‡çš„å®Œæ•´æ€§",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    parser.add_argument(
        "--input",
        type=str,
        required=True,
        help="è¾“å…¥ JSONL æ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "--output",
        type=str,
        required=True,
        help="è¾“å‡º JSONL æ–‡ä»¶è·¯å¾„ï¼ˆåªåŒ…å«æœ‰æ•ˆå›¾ç‰‡ï¼‰"
    )
    parser.add_argument(
        "--image-root",
        type=str,
        default=None,
        help="å›¾ç‰‡æ ¹ç›®å½•ï¼ˆç”¨äºè§£æç›¸å¯¹è·¯å¾„ï¼‰"
    )
    parser.add_argument(
        "--remove-missing",
        action="store_true",
        help="ç§»é™¤ç¼ºå¤±å›¾ç‰‡çš„è®°å½•ï¼ˆé»˜è®¤ä¿ç•™ï¼‰"
    )
    parser.add_argument(
        "--backup-original",
        action="store_true",
        help="å¤‡ä»½åŸå§‹æ–‡ä»¶ï¼ˆæ·»åŠ  .backup åç¼€ï¼‰"
    )
    
    args = parser.parse_args()
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_dir = os.path.dirname(args.output)
    if output_dir and not os.path.exists(output_dir):
        os.makedirs(output_dir, exist_ok=True)
    
    main(args)

